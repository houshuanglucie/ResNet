{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Residual Learning for Image Recognition\n",
    "\n",
    "**Notebook author: Shuang HOU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of 2015, Microsoft Research Asia released a paper titled [\"Deep Residual Learning for Image Recognition\"](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), authored by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun. The paper achieved state-of-the-art results in Image classification and detection, winning the ImageNet and COCO competitions. This notebook is an implementation of the Residual Network (**ResNet** for short) in PyTorch based on this paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is prepared for students who have participated in the AML course (or a fairly close course). It supposes a basic knowledge of Deep Learning and Convolutional Neural Networks, which have been introduced in the previous courses ([DL](https://github.com/SupaeroDataScience/deep-learning/tree/main/deep), [CNN](https://github.com/fchouteau/isae-practical-deep-learning)), you can refer to them if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents:**\n",
    "0. [Preparation](#sec0)\n",
    "1. [Problem introduction](#sec1)\n",
    "2. [Construction of ResNet](#sec2)\n",
    "    1. [Residual Learning](#sec2-1)\n",
    "    2. [Identity Mapping by Shortcuts](#sec2-2)\n",
    "    3. [Network Architectures](#sec2-3)\n",
    "3. [Experiments](#sec3)\n",
    "    1. [ImageNet Classification](#sec3-1)\n",
    "    2. [CIFAR-10 and Analysis](#sec3-2)\n",
    "4. [Conclusion](#sec4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec0\"></a>0. Preparation\n",
    "\n",
    "In this notebook, we'll be using `torch` and `torchvision`, which we have already used in previous AML courses. Run the following code blocks to install the necessary packages and verify that everything is working by importing everything. \n",
    "\n",
    "Please refer to the [PyTorch](https://pytorch.org/get-started/locally/) website for installation instructions if necessary. We'll also be using packages `sklearn`, `numpy`, and `matplotlib`. \n",
    "\n",
    "Note that this notebook is fairly compute intensive and might be better [run in Google Colab]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as Data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec1\"></a>1. Problem introduction\n",
    "\n",
    "From experience, the depth of the network is crucial to the performance of the model. When the number of network layers is increased, the network can extract more complex feature patterns, so theoretically better results can be achieved when the model is deeper. \n",
    "\n",
    "But the experiment found that the deep network has a *degradation* problem: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly. This phenomenon can be seen directly in Figure 1 which shows the training error (left) and test error (right) on CIFAR-10 with 20-layer and 56-layer \"plain\" networks. The deeper network has higher training error, and thus test error. This is not caused by overfitting, because the training error of the 56-layer network is also high.\n",
    "\n",
    "<img src=\"img/degradation.JPG\" width=\"50%\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 1. Training error (left) and test error (right) on CIFAR-10 with 20-layer and 56-layer \"plain\" networks.<br>\n",
    "    The deeper network has higher training error, and thus test error.</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Think about this question:**<br>\n",
    "How to effectively solve the \"degradation\" problem caused by the increase in network depth?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#answer1\" data-toggle=\"collapse\"><b>Ready to see the answer? (click to expand)</b></a><br>\n",
    "<div id=\"answer1\" class=\"collapse\">\n",
    "\n",
    "The problem of degradation is mainly due to the increase in network depth. During model training, the gradient cannot be effectively transmitted to the shallow network, resulting in [vanishing/exploding gradients](). **Batch Normalization** (BN) changes the data distribution by normalizing the output data, which is a forward process to solve the vanishing/exploding gradients problem. The residual network (ResNet) directly connects the shallow network and the deep network by adding **shortcut connection** (Identity Map), so that the gradient can be well transmitted to the shallow layer.\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic building block for Plain Network\n",
    "    \n",
    "    Parameters：\n",
    "        - in_channel: Number of input channel\n",
    "        - out_channel: Number of output channel\n",
    "        - stride: Number of stride \n",
    "        - downsample: \"None\" for identity downsample, otherwise for a real downsample\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 1    # Record whether the number of convolution kernels in each layer has changed\n",
    " \n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(PlainBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)  # 有无bias对bn没多大影响\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    " \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    " \n",
    "        self.downsample = downsample\n",
    " \n",
    "    def forward(self, x):\n",
    "        identity = x      # Record the output of the last residual block\n",
    "        \n",
    "        if self.downsample is not None:  # Determine if need to downsample for dimension matching\n",
    "            identity = self.downsample(x)\n",
    " \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    " \n",
    "        out = self.relu(out)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\"></a>2. Construction of ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"sec2-1\"></a>2.1. Residual Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response to the \"degradation\" problem, the author Dr. He proposed a **deep residual learning** framework, which uses a multi-layer network to fit a residual mapping.\n",
    "\n",
    "Formally, denoting the desired underlying mapping as $H(x)$, we let the stacked nonlinear layers fit another mapping:\n",
    "\n",
    "$$F(x) := H(x)−x$$ \n",
    "\n",
    "The original mapping is recast into:\n",
    "\n",
    "$$F(x)+x$$. \n",
    "\n",
    "We hypothesize that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping. To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers.\n",
    "\n",
    "The formulation of $F(x)+x$ can be realized by feedforward neural networks with \"**[shortcut connections]()**\". Shortcut connections are those skipping one or more layers. For the case in paper, the shortcut connections simply perform identity mapping, and their outputs are added to the outputs of the stacked layers. \n",
    "\n",
    "Figure 2 shows a building block of residual learning in the deep residual network:\n",
    "\n",
    "<img src=\"img/2-layer building block.JPG\" width=\"340px\">\n",
    "\n",
    "<center><font size=1.5><br>Figure 2. Residual learning: a building block.</font></center>\n",
    "\n",
    "Identity shortcut connections add neither extra parameter nor computational complexity. The entire network can still be trained end-to-end by SGD with backpropagation, and can be easily implemented using common libraries (e.g., [Caffe]) without modifying the solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**In brief:**<br>\n",
    "- If identity mappings are added, a deeper network will not perform worse than a shallow network.\n",
    "- It is difficult to learn identify mapings in a network structure composed of multiple non-linear layers.\n",
    "- If identity mapings is the optimal link method, then the weight parameters of $F(x)$ will tend to $0$.\n",
    "- If the optimal mapping is close to identity mappings, it is much easier to find the $F(x)$ corresponding to the identity mappings (initial parameters near 0) during optimization than to approximately fit a completely new function.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A basic building block for 18/34-layer ResNet.\n",
    "    \n",
    "    Parameters：\n",
    "        - in_channel: Number of input channel\n",
    "        - out_channel: Number of output channel\n",
    "        - stride: Number of stride \n",
    "        - downsample: \"None\" for identity downsample, otherwise for a real downsample\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 1    # Record whether the number of convolution kernels in each layer has changed\n",
    " \n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    " \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    " \n",
    "        self.downsample = downsample\n",
    " \n",
    "    def forward(self, x):\n",
    "        residual = x      # Record the output of the last residual block\n",
    " \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:   # Determine if need to downsample for dimension matching\n",
    "            residual = self.downsample(x)\n",
    " \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"sec2-2\"></a>2.2. Identity Mapping by Shortcuts\n",
    "\n",
    "Two connection methods are proposed for shortcut connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1:**\n",
    "\n",
    "$$y = F(x,\\{W_{i}\\}) + x$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x$ represents the input vector of the building block for the layers considered.\n",
    "- $y$ represents the output vector of the building block for the layers considered.\n",
    "- $F(x,\\{W_{i}\\})$ represents the residual mapping to be learned, which is the superposition of multiple nonlinear convolutional layers.<br>\n",
    "  For the example in figure above that has two layers, $F = W_2 \\sigma(W_1 x)$ in which $\\sigma$ represents the nonlinear activation function ReLU, and the biases are omitted for simplifying notations.\n",
    "- $F+x$ means shortcut connection, which corresponds to the addition of each pixel.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Note:** This network structure introduce neither extra parameter nor computation complexity. This is not only attractive in practice but also important in the comparisons between plain and residual networks. We can fairly compare plain/residual networks that simultaneously have the same number of parameters, depth, width, and computational cost (except for the negligible element-wise addition).\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2:**\n",
    "\n",
    "In method 1, the dimensions of $x$ and $F$ must be equal. If this is not the case (e.g., when changing the input/output channels), we can perform a linear projection $W_s$ by the shortcut connections to match the dimensions:\n",
    "\n",
    "$$y = F(x,\\{W_{i}\\}) + W_{s}x$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x$ represents the input vector of the building block for the layers considered.\n",
    "- $y$ represents the output vector of the building block for the layers considered.\n",
    "- $F(x,\\{W_{i}\\})$ represents the residual mapping to be learned, which is the superposition of multiple nonlinear convolutional layers.<br>\n",
    "  For the example in figure above that has two layers, $F = W_2 \\sigma(W_1 x)$ in which $\\sigma$ represents the nonlinear activation function ReLU, and the biases are omitted for simplifying notations.\n",
    "- $F+x$ means shortcut connection, which corresponds to the addition of each pixel.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Note:** The identity mapping is sufficient for addressing the degradation problem and is economical, thus $W_s$ will be only used when matching dimensions.\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also mentioned in paper that, for $F(x,\\{W_{i}\\})$, it should not be limited to the two-layer convolution connection mentioned above, it can be more diverse, such as the three-layer building block on the right of Figure 3. One such small unit is called a *block*. When building a deep network structure, the author calls the second structure *bottleneck* building block.\n",
    "\n",
    "<img src=\"img/3-layer building block.JPG\">\n",
    "\n",
    "<center><font size=1.5><br>Figure 3. Two different building blocks for residual learning.<br> \n",
    "    Left: a building block (on 56 $\\times$ 56 feature maps) as in Figure 4 for ResNet34.<br>\n",
    "    Right: a \"bottleneck\" building block for ResNet-50/101/152.</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A \"bottleneck\" building block for 50/101/152-layer ResNet.\n",
    "    \n",
    "    Parameters：\n",
    "        - in_channel: Number of input channel\n",
    "        - out_channel: Number of output channel\n",
    "        - stride: Number of stride \n",
    "        - downsample: \"None\" for identity downsample, otherwise for a real downsample\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 4       # The number of convolution kernels in the third layer (256, 512, 1024, 2048) \n",
    "                        # is 4 times the number of convolution kernels in the first or second layer (64, 128, 256, 512)\n",
    " \n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=1, stride=1, bias=False)  # Squeeze channels for dimensionality reduce\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    " \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    " \n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel*self.expansion,\n",
    "                               kernel_size=1, stride=1, bias=False)  # Unsqueeze channels for dimensionality increase\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)\n",
    " \n",
    "        self.downsample = downsample\n",
    " \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    " \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    " \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"sec2-3\"></a>2.3. Network Architectures\n",
    "\n",
    "The subsequent implementation part is mainly to compare the two network structures of **plain nets** and **residual nets**, so this part focuses on the description of these two network structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/plain-res nets.jpg\" width=\"55%\">\n",
    "\n",
    "<center><font size=1.5><br>Figure 4. Example network architectures for ImageNet.<br>\n",
    "    Left: the [VGG-19] model(19.6 billion FLOPs) as a reference.<br> \n",
    "    Middle: a plain network with 34 parameter layers (3.6 billion FLOPs).<br>\n",
    "    Right: a residual network with 34 parameter layers (3.6 billionFLOPs).<br>\n",
    "    The dotted shortcuts increase dimensions.</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plain Network**\n",
    "\n",
    "The plain baselines (Figure 4, middle) are mainly inspired by the philosophy of [VGG nets] (Figure 4, left). The convolutional layers mostly have $3 \\times 3$ filters and follow two simple design rules: (i) for the same output feature map size, the layers have the same number of filters; and (ii) if the feature map size is halved, the number of filters is doubled so as to preserve the time complexity per layer. We perform downsampling directly by convolutional layers that have a stride of 2. The network ends with a global average pooling layer and a 1000-way fully-connected layer with softmax. The total number of weighted layers is 34 (Figure 4, middle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual Network**\n",
    "\n",
    "Based on the above plain network, we insert shortcut connections (Figure 4, right) which turn the network into its counterpart residual version. The identity shortcuts (method 1) can be directly used when the input and output are of the same dimensions (solid line shortcuts in Figure 4). When the dimensions increase (dotted line shortcuts in Figure 4), we consider two options: (A) The shortcut still performs identity mapping, with extra zero entries padded for increasing dimensions. This option introduces no extra parameter; (B) The projection shortcut in method 2 is used to match dimensions (done by 1 $\\times$ 1 convolutions). For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of ResNet architecture.\n",
    "    \n",
    "    Parameters：\n",
    "        - block: \"BasicBlock\" for 18/34-layer ResNet, \"Bottleneck\" for 50/101/152-layer ResNet\n",
    "        - blocks_num: The number of residual layers, for example, [3,4,6,3] for the 34-layer ResNet\n",
    "        - include_top: Facilitate the construction of more complex networks on the basis of resnet in the future\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, block, blocks_num, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channel = 64    # The number of output channels in the previous layer, also the number of input channels in this layer\n",
    " \n",
    "        #  part 1: conv1 + maxpooling\n",
    "        self.conv1 = nn.Conv2d(1, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    " \n",
    "        #  part 2: conv2,3,4,5\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
    " \n",
    "        #  part 3: avgpooling + fully connected layer\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    " \n",
    "        #  Initialization of the convolutional layer\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    " \n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            #  The dotted line in the ResNet architecture\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    " \n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
    "        self.in_channel = channel * block.expansion\n",
    " \n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel, channel))\n",
    " \n",
    "        return nn.Sequential(*layers)   # Convert list into non-keyword parameters\n",
    " \n",
    "    def forward(self, x):\n",
    " \n",
    "        # part 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)\n",
    " \n",
    "        # part 2\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    " \n",
    "        # part 3\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct a 34-layer ResNet with \"BasicBlock\" and a 101-layer ResNet with \"Bottleneck\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, num_classes=10):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (boolean): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plainnet34(num_classes=1000, include_top=True):\n",
    "    return ResNet(PlainBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(num_classes=1000, include_top=True):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet101(num_classes=1000, include_top=True):\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec3\"></a>3. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model\", type=str, default='resnet18', help=\"model\")\n",
    "parser.add_argument(\"--patience\", type=int, default=3, help=\"early stopping patience\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=256, help=\"batch size\")\n",
    "parser.add_argument(\"--nepochs\", type=int, default=200, help=\"max epochs\")\n",
    "parser.add_argument(\"--nworkers\", type=int, default=4, help=\"number of workers\")\n",
    "parser.add_argument(\"--seed\", type=int, default=1, help=\"random seed\")\n",
    "# parser.add_argument(\"--data\", type=str, default='MNIST', help=\"MNIST, or FashionMNIST\")\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "# Set up the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Training on {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds. If using numpy this must be seeded too.\n",
    "torch.manual_seed(1)\n",
    "if device== 'cuda:0':\n",
    "    torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_text = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms.\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trainset = torchvision.datasets.FashionMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "trainset, full_validset = torch.utils.data.random_split(full_trainset, (10000, 50000))\n",
    "validset, _ = torch.utils.data.random_split(full_validset, (1000, 49000))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=512, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images and labels with parameter batch_size=4\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "for i in range(len(images)):\n",
    "    l = labels[i].numpy()\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title('%d: %s' % (l, labels_text[l]))\n",
    "    plt.imshow(images[i].numpy()[0], cmap='Greys')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def validation(net):\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    return valid_loss\n",
    "\n",
    "def train(net):\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "    train_history = []\n",
    "    valid_history = []\n",
    "    for epoch in range(30):\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        valid_loss = validation(net)\n",
    "        train_history.append(train_loss)\n",
    "        valid_history.append(valid_loss)\n",
    "        print('Epoch %02d: train loss %0.5f, validation loss %0.5f' % (epoch, train_loss, valid_loss))\n",
    "    return train_history, valid_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(pretrained=False, num_classes=10)\n",
    "# net = net.to(device)\n",
    "train_history, valid_history = train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(net, loader, criterion, optimizer, train = True):\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    running_history = []\n",
    "\n",
    "    # Set mode\n",
    "    if train:\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        per_run_loss = 0.0\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Pass to gpu or cpu\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            output = net(inputs)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "        # If on train backpropagate\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate stats\n",
    "        per_run_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += torch.sum(pred == labels.detach())\n",
    "        running_history.append(running_loss)\n",
    "        if train:\n",
    "            print('Epoch %02d: train loss %0.5f' % (epoch, per_run_loss))\n",
    "        else:\n",
    "            print('Epoch %02d: validation loss %0.5f' % (epoch, per_run_loss))\n",
    "        \n",
    "    return running_loss / len(loader), running_accuracy.double() / len(loader.dataset), running_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init network, criterion and early stopping\n",
    "net = resnet18(pretrained=False, num_classes=10)\n",
    "# net = net.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "import time\n",
    "# import utils\n",
    "\n",
    "patience = 3\n",
    "best_loss = 1e4\n",
    "    \n",
    "for epoch in range(30):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc, train_history = run_model(net, trainloader,\n",
    "                                      criterion, optimizer)\n",
    "    val_loss, val_acc, valid_history = run_model(net, validloader,\n",
    "                                  criterion, optimizer, False)\n",
    "    end = time.time()\n",
    "\n",
    "    # print stats\n",
    "    stats = \"\"\"Epoch: {}\\t train loss: {:.3f}, train acc: {:.3f}\\t\n",
    "            val loss: {:.3f}, val acc: {:.3f}\\t\n",
    "            time: {:.1f}s\"\"\".format(epoch, train_loss, train_acc, val_loss,\n",
    "                                        val_acc, end - start)\n",
    "    print(stats)\n",
    "\n",
    "#     # early stopping and save best model\n",
    "#     if val_loss < best_loss:\n",
    "#         best_loss = val_loss\n",
    "#         patience = patience\n",
    "#         utils.save_model({\n",
    "#             'arch': net,\n",
    "#             'state_dict': net.state_dict()\n",
    "#         }, 'saved-models/{}-run-{}.pth.tar'.format(net, run))\n",
    "#     else:\n",
    "#         patience -= 1\n",
    "#         if patience == 0:\n",
    "#             print('Run out of patience!')\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**由于jupyter notebook运行不起来，因此我转到colab中运行了一下。<br>用CPU运行，1个epoch的大约需要5min；用GPU运行，1个epoch大约需要6s。**\n",
    "\n",
    "**Epoch: 1**\t train loss: 0.460, train acc: 0.833\t\n",
    "            val loss: 0.706, val acc: 0.749\t\n",
    "            time: 283.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_predictions(net):\n",
    "    # validloader = torch.utils.data.DataLoader(validset, batch_size=4, shuffle=False)\n",
    "    all_labels = np.array([])\n",
    "    predictions = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels = np.append(all_labels, labels.numpy())\n",
    "            predictions = np.append(predictions, predicted.numpy())\n",
    "    return all_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid, predictions = get_valid_predictions(net)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print('Accuracy: ', accuracy_score(predictions, y_valid))\n",
    "print(classification_report(predictions, y_valid, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**以下是colab中的运行结果：**\n",
    "\n",
    "Accuracy:  0.749<br>\n",
    "                \n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "    T-shirt/top       0.84      0.60      0.70       129\n",
    "     Trouser       0.95      0.99      0.97        88\n",
    "    Pullover       0.85      0.68      0.76       141\n",
    "       Dress       0.56      0.97      0.71        64\n",
    "        Coat       0.57      0.65      0.61        89\n",
    "      Sandal       0.40      1.00      0.57        37\n",
    "       Shirt       0.46      0.41      0.43        91\n",
    "     Sneaker       0.96      0.66      0.78       157\n",
    "         Bag       0.90      0.96      0.93        92\n",
    "    Ankle boot       0.93      0.92      0.92       112\n",
    "\n",
    "    accuracy                           0.75      1000\n",
    "    macro avg       0.74      0.78      0.74      1000\n",
    "    weighted avg       0.79      0.75      0.75      1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val(train, valid):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.set_ylabel('Training', color=color)\n",
    "    ax1.plot(train, color=color)\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Validation', color=color)\n",
    "    ax2.plot(valid, color=color)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plot_train_val(train_history, valid_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对测试集进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.FashionMNIST(root='../data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(net):\n",
    "    # Model = model.__dict__['resnet18']().to(device)\n",
    "    # Model.load_state_dict(torch.load(path)['state_dict'])\n",
    "    with torch.no_grad():  ## 禁止使用反传\n",
    "        pred = []\n",
    "        all_label = []\n",
    "        for batch_idx, (data, label) in enumerate(testloader):\n",
    "            batch_x, batch_y = data.to(device), label.to(device)\n",
    "            batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "            output = net(batch_x)\n",
    "            \n",
    "            pred2 = output.max(1, keepdim=True)[1]\n",
    "            pred2 = pred2.cpu().numpy()  \n",
    "            for ii in range(len(pred2)):\n",
    "                pred.append((pred2[ii])[0])\n",
    "            all_label = np.append(all_label, batch_y.numpy())\n",
    "\n",
    "    return pred, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, y_test = run_test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print('Accuracy: ', accuracy_score(pred, y_test))\n",
    "print(classification_report(pred, y_test, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**colab中的运行epoch=1的结果：**\n",
    "\n",
    "Accuracy:  0.779<br>\n",
    "              \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    T-shirt/top       0.89      0.65      0.75      1401\n",
    "     Trouser       0.96      0.99      0.98       982\n",
    "    Pullover       0.82      0.69      0.75      1186\n",
    "       Dress       0.52      0.98      0.68       547\n",
    "        Coat       0.69      0.65      0.67      1059\n",
    "      Sandal       0.51      1.00      0.67       492\n",
    "       Shirt       0.57      0.58      0.57       959\n",
    "     Sneaker       0.96      0.69      0.80      1414\n",
    "         Bag       0.91      0.95      0.93       972\n",
    "    Ankle boot       0.95      0.93      0.94       988\n",
    "\n",
    "    accuracy                           0.78     10000\n",
    "    macro avg       0.78      0.81      0.77     10000\n",
    "    weighted avg       0.82      0.78      0.78     10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769ea9cb0ca04def9f920ea7436e58fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2399b3058653440390a3d4ec9a23ff98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752e76bbdb854910b1c370c8c2206e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5dc851fe984d7e8137acf0ef5db1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "train_data: torch.Size([10000, 28, 28])\n",
      "train_labels: torch.Size([10000])\n",
      "test_data: torch.Size([10000, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    './mnist', train=True, transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    ]), download=True\n",
    ")\n",
    "\n",
    "train_data.data = train_data.data[:10000]\n",
    "train_data.targets = train_data.targets[:10000]\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    './mnist', train=False, transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    ]), download=True\n",
    ")\n",
    "\n",
    "print(\"train_data:\", train_data.train_data.size())\n",
    "print(\"train_labels:\", train_data.train_labels.size())\n",
    "print(\"test_data:\", test_data.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (right): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=32)\n",
    "\n",
    "model = ResNet18()\n",
    "if if_use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "batch:1,Train Loss: 2.374657, Acc: 0.062500\n",
      "batch:2,Train Loss: 6.123889, Acc: 0.156250\n",
      "batch:3,Train Loss: 19.508154, Acc: 0.125000\n",
      "batch:4,Train Loss: 13.292258, Acc: 0.218750\n",
      "batch:5,Train Loss: 4.874920, Acc: 0.125000\n",
      "batch:6,Train Loss: 6.002936, Acc: 0.062500\n",
      "batch:7,Train Loss: 15.337273, Acc: 0.093750\n",
      "batch:8,Train Loss: 5.083591, Acc: 0.156250\n",
      "batch:9,Train Loss: 7.783920, Acc: 0.093750\n",
      "batch:10,Train Loss: 9.707572, Acc: 0.125000\n",
      "batch:11,Train Loss: 6.786269, Acc: 0.156250\n",
      "batch:12,Train Loss: 6.968081, Acc: 0.312500\n",
      "batch:13,Train Loss: 5.258401, Acc: 0.125000\n",
      "batch:14,Train Loss: 7.909595, Acc: 0.125000\n",
      "batch:15,Train Loss: 3.568305, Acc: 0.250000\n",
      "batch:16,Train Loss: 3.798988, Acc: 0.218750\n",
      "batch:17,Train Loss: 5.174158, Acc: 0.093750\n",
      "batch:18,Train Loss: 2.668407, Acc: 0.437500\n",
      "batch:19,Train Loss: 2.718485, Acc: 0.437500\n",
      "batch:20,Train Loss: 3.481237, Acc: 0.218750\n",
      "batch:21,Train Loss: 2.669489, Acc: 0.312500\n",
      "batch:22,Train Loss: 3.429018, Acc: 0.156250\n",
      "batch:23,Train Loss: 2.237911, Acc: 0.312500\n",
      "batch:24,Train Loss: 2.637118, Acc: 0.187500\n",
      "batch:25,Train Loss: 1.947347, Acc: 0.375000\n",
      "batch:26,Train Loss: 1.935269, Acc: 0.312500\n",
      "batch:27,Train Loss: 1.713541, Acc: 0.312500\n",
      "batch:28,Train Loss: 1.915364, Acc: 0.437500\n",
      "batch:29,Train Loss: 1.760914, Acc: 0.437500\n",
      "batch:30,Train Loss: 1.388388, Acc: 0.625000\n",
      "batch:31,Train Loss: 1.067319, Acc: 0.593750\n",
      "batch:32,Train Loss: 1.149077, Acc: 0.656250\n",
      "batch:33,Train Loss: 1.022259, Acc: 0.562500\n",
      "batch:34,Train Loss: 0.995527, Acc: 0.656250\n",
      "batch:35,Train Loss: 0.942225, Acc: 0.687500\n",
      "batch:36,Train Loss: 1.266877, Acc: 0.656250\n",
      "batch:37,Train Loss: 1.142909, Acc: 0.593750\n",
      "batch:38,Train Loss: 0.614996, Acc: 0.875000\n",
      "batch:39,Train Loss: 0.836040, Acc: 0.781250\n",
      "batch:40,Train Loss: 0.974448, Acc: 0.718750\n",
      "batch:41,Train Loss: 0.860543, Acc: 0.625000\n",
      "batch:42,Train Loss: 0.676696, Acc: 0.750000\n",
      "batch:43,Train Loss: 0.998912, Acc: 0.718750\n",
      "batch:44,Train Loss: 1.117538, Acc: 0.781250\n",
      "batch:45,Train Loss: 0.598522, Acc: 0.781250\n",
      "batch:46,Train Loss: 0.962399, Acc: 0.718750\n",
      "batch:47,Train Loss: 0.341898, Acc: 0.843750\n",
      "batch:48,Train Loss: 1.658254, Acc: 0.562500\n",
      "batch:49,Train Loss: 0.725446, Acc: 0.718750\n",
      "batch:50,Train Loss: 1.020667, Acc: 0.687500\n",
      "batch:51,Train Loss: 0.836885, Acc: 0.687500\n",
      "batch:52,Train Loss: 0.665846, Acc: 0.843750\n",
      "batch:53,Train Loss: 0.607943, Acc: 0.843750\n",
      "batch:54,Train Loss: 1.115294, Acc: 0.718750\n",
      "batch:55,Train Loss: 0.370771, Acc: 0.906250\n",
      "batch:56,Train Loss: 0.416092, Acc: 0.781250\n",
      "batch:57,Train Loss: 1.062608, Acc: 0.656250\n",
      "batch:58,Train Loss: 0.748255, Acc: 0.781250\n",
      "batch:59,Train Loss: 0.748196, Acc: 0.750000\n",
      "batch:60,Train Loss: 0.349035, Acc: 0.906250\n",
      "batch:61,Train Loss: 0.594077, Acc: 0.843750\n",
      "batch:62,Train Loss: 0.567152, Acc: 0.812500\n",
      "batch:63,Train Loss: 0.764468, Acc: 0.750000\n",
      "batch:64,Train Loss: 0.426165, Acc: 0.875000\n",
      "batch:65,Train Loss: 0.415087, Acc: 0.906250\n",
      "batch:66,Train Loss: 0.478439, Acc: 0.843750\n",
      "batch:67,Train Loss: 0.526708, Acc: 0.843750\n",
      "batch:68,Train Loss: 0.620887, Acc: 0.812500\n",
      "batch:69,Train Loss: 0.567903, Acc: 0.750000\n",
      "batch:70,Train Loss: 0.846463, Acc: 0.781250\n",
      "batch:71,Train Loss: 0.489476, Acc: 0.875000\n",
      "batch:72,Train Loss: 0.955357, Acc: 0.812500\n",
      "batch:73,Train Loss: 0.260621, Acc: 0.875000\n",
      "batch:74,Train Loss: 1.087671, Acc: 0.781250\n",
      "batch:75,Train Loss: 0.315470, Acc: 0.875000\n",
      "batch:76,Train Loss: 0.358279, Acc: 0.906250\n",
      "batch:77,Train Loss: 0.349828, Acc: 0.875000\n",
      "batch:78,Train Loss: 0.260369, Acc: 0.875000\n",
      "batch:79,Train Loss: 0.185224, Acc: 0.906250\n",
      "batch:80,Train Loss: 0.196940, Acc: 0.968750\n",
      "batch:81,Train Loss: 0.209484, Acc: 0.968750\n",
      "batch:82,Train Loss: 0.667545, Acc: 0.843750\n",
      "batch:83,Train Loss: 0.746357, Acc: 0.781250\n",
      "batch:84,Train Loss: 0.667442, Acc: 0.843750\n",
      "batch:85,Train Loss: 0.614867, Acc: 0.781250\n",
      "batch:86,Train Loss: 0.648872, Acc: 0.843750\n",
      "batch:87,Train Loss: 0.355949, Acc: 0.875000\n",
      "batch:88,Train Loss: 0.727277, Acc: 0.781250\n",
      "batch:89,Train Loss: 0.540263, Acc: 0.812500\n",
      "batch:90,Train Loss: 0.847820, Acc: 0.843750\n",
      "batch:91,Train Loss: 0.585054, Acc: 0.812500\n",
      "batch:92,Train Loss: 0.369884, Acc: 0.937500\n",
      "batch:93,Train Loss: 0.356722, Acc: 0.812500\n",
      "batch:94,Train Loss: 0.122666, Acc: 0.968750\n",
      "batch:95,Train Loss: 0.391408, Acc: 0.875000\n",
      "batch:96,Train Loss: 0.344378, Acc: 0.843750\n",
      "batch:97,Train Loss: 0.441753, Acc: 0.906250\n",
      "batch:98,Train Loss: 0.424758, Acc: 0.843750\n",
      "batch:99,Train Loss: 0.189533, Acc: 0.937500\n",
      "batch:100,Train Loss: 0.170411, Acc: 0.937500\n",
      "batch:101,Train Loss: 0.238961, Acc: 0.968750\n",
      "batch:102,Train Loss: 0.537517, Acc: 0.812500\n",
      "batch:103,Train Loss: 0.088800, Acc: 0.968750\n",
      "batch:104,Train Loss: 0.253567, Acc: 0.875000\n",
      "batch:105,Train Loss: 0.280134, Acc: 0.875000\n",
      "batch:106,Train Loss: 0.234492, Acc: 0.968750\n",
      "batch:107,Train Loss: 0.156020, Acc: 0.937500\n",
      "batch:108,Train Loss: 0.045393, Acc: 1.000000\n",
      "batch:109,Train Loss: 0.599164, Acc: 0.906250\n",
      "batch:110,Train Loss: 0.102281, Acc: 0.968750\n",
      "batch:111,Train Loss: 0.757098, Acc: 0.812500\n",
      "batch:112,Train Loss: 0.223099, Acc: 0.937500\n",
      "batch:113,Train Loss: 0.560938, Acc: 0.875000\n",
      "batch:114,Train Loss: 0.278194, Acc: 0.937500\n",
      "batch:115,Train Loss: 0.470362, Acc: 0.812500\n",
      "batch:116,Train Loss: 0.257272, Acc: 0.875000\n",
      "batch:117,Train Loss: 0.274676, Acc: 0.937500\n",
      "batch:118,Train Loss: 0.156663, Acc: 0.937500\n",
      "batch:119,Train Loss: 0.067367, Acc: 0.968750\n",
      "batch:120,Train Loss: 0.470823, Acc: 0.812500\n",
      "batch:121,Train Loss: 0.616343, Acc: 0.812500\n",
      "batch:122,Train Loss: 0.364869, Acc: 0.906250\n",
      "batch:123,Train Loss: 0.168778, Acc: 0.937500\n",
      "batch:124,Train Loss: 0.272859, Acc: 0.875000\n",
      "batch:125,Train Loss: 0.918549, Acc: 0.843750\n",
      "batch:126,Train Loss: 0.495074, Acc: 0.875000\n",
      "batch:127,Train Loss: 1.294970, Acc: 0.781250\n",
      "batch:128,Train Loss: 0.513708, Acc: 0.937500\n",
      "batch:129,Train Loss: 0.106812, Acc: 0.937500\n",
      "batch:130,Train Loss: 0.645351, Acc: 0.843750\n",
      "batch:131,Train Loss: 0.890301, Acc: 0.812500\n",
      "batch:132,Train Loss: 0.471426, Acc: 0.937500\n",
      "batch:133,Train Loss: 0.413791, Acc: 0.812500\n",
      "batch:134,Train Loss: 1.056974, Acc: 0.843750\n",
      "batch:135,Train Loss: 0.352706, Acc: 0.906250\n",
      "batch:136,Train Loss: 0.859079, Acc: 0.750000\n",
      "batch:137,Train Loss: 0.377452, Acc: 0.875000\n",
      "batch:138,Train Loss: 0.340982, Acc: 0.906250\n",
      "batch:139,Train Loss: 0.398196, Acc: 0.906250\n",
      "batch:140,Train Loss: 0.436363, Acc: 0.843750\n",
      "batch:141,Train Loss: 0.404410, Acc: 0.843750\n",
      "batch:142,Train Loss: 0.040406, Acc: 1.000000\n",
      "batch:143,Train Loss: 0.058166, Acc: 1.000000\n",
      "batch:144,Train Loss: 0.517835, Acc: 0.781250\n",
      "batch:145,Train Loss: 0.018426, Acc: 1.000000\n",
      "batch:146,Train Loss: 0.674114, Acc: 0.843750\n",
      "batch:147,Train Loss: 0.321725, Acc: 0.812500\n",
      "batch:148,Train Loss: 0.440840, Acc: 0.968750\n",
      "batch:149,Train Loss: 0.136948, Acc: 0.937500\n",
      "batch:150,Train Loss: 0.290831, Acc: 0.906250\n",
      "batch:151,Train Loss: 0.068433, Acc: 0.968750\n",
      "batch:152,Train Loss: 0.048366, Acc: 1.000000\n",
      "batch:153,Train Loss: 0.121687, Acc: 0.968750\n",
      "batch:154,Train Loss: 0.044085, Acc: 1.000000\n",
      "batch:155,Train Loss: 0.637936, Acc: 0.812500\n",
      "batch:156,Train Loss: 0.073744, Acc: 0.968750\n",
      "batch:157,Train Loss: 0.276545, Acc: 0.937500\n",
      "batch:158,Train Loss: 0.394523, Acc: 0.906250\n",
      "batch:159,Train Loss: 0.119533, Acc: 0.937500\n",
      "batch:160,Train Loss: 0.293935, Acc: 0.875000\n",
      "batch:161,Train Loss: 0.747539, Acc: 0.843750\n",
      "batch:162,Train Loss: 0.184340, Acc: 0.937500\n",
      "batch:163,Train Loss: 0.355284, Acc: 0.843750\n",
      "batch:164,Train Loss: 0.551452, Acc: 0.906250\n",
      "batch:165,Train Loss: 0.802182, Acc: 0.875000\n",
      "batch:166,Train Loss: 0.101995, Acc: 0.968750\n",
      "batch:167,Train Loss: 0.187606, Acc: 0.937500\n",
      "batch:168,Train Loss: 0.356200, Acc: 0.906250\n",
      "batch:169,Train Loss: 0.302759, Acc: 0.906250\n",
      "batch:170,Train Loss: 0.389239, Acc: 0.875000\n",
      "batch:171,Train Loss: 0.324865, Acc: 0.906250\n",
      "batch:172,Train Loss: 0.311231, Acc: 0.812500\n",
      "batch:173,Train Loss: 0.144701, Acc: 0.968750\n",
      "batch:174,Train Loss: 0.494214, Acc: 0.750000\n",
      "batch:175,Train Loss: 0.106997, Acc: 0.937500\n",
      "batch:176,Train Loss: 0.998723, Acc: 0.875000\n",
      "batch:177,Train Loss: 0.884881, Acc: 0.812500\n",
      "batch:178,Train Loss: 0.517969, Acc: 0.875000\n",
      "batch:179,Train Loss: 0.114327, Acc: 0.937500\n",
      "batch:180,Train Loss: 0.609461, Acc: 0.843750\n",
      "batch:181,Train Loss: 0.692862, Acc: 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:182,Train Loss: 0.412537, Acc: 0.843750\n",
      "batch:183,Train Loss: 0.203275, Acc: 0.968750\n",
      "batch:184,Train Loss: 0.417183, Acc: 0.875000\n",
      "batch:185,Train Loss: 0.030099, Acc: 1.000000\n",
      "batch:186,Train Loss: 0.200837, Acc: 0.937500\n",
      "batch:187,Train Loss: 0.127633, Acc: 0.937500\n",
      "batch:188,Train Loss: 0.048370, Acc: 0.968750\n",
      "batch:189,Train Loss: 0.322275, Acc: 0.937500\n",
      "batch:190,Train Loss: 0.079107, Acc: 0.968750\n",
      "batch:191,Train Loss: 0.252487, Acc: 0.906250\n",
      "batch:192,Train Loss: 0.180565, Acc: 0.937500\n",
      "batch:193,Train Loss: 0.293501, Acc: 0.906250\n",
      "batch:194,Train Loss: 0.387668, Acc: 0.937500\n",
      "batch:195,Train Loss: 0.668451, Acc: 0.843750\n",
      "batch:196,Train Loss: 0.509568, Acc: 0.812500\n",
      "batch:197,Train Loss: 0.283848, Acc: 0.906250\n",
      "batch:198,Train Loss: 0.103716, Acc: 0.968750\n",
      "batch:199,Train Loss: 0.071170, Acc: 0.968750\n",
      "batch:200,Train Loss: 0.123919, Acc: 0.968750\n",
      "batch:201,Train Loss: 0.198210, Acc: 0.937500\n",
      "batch:202,Train Loss: 0.197717, Acc: 0.875000\n",
      "batch:203,Train Loss: 0.278053, Acc: 0.875000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-55c472262dd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-c29383d7fd11>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-fe6608257d94>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        batch_x, batch_y = Variable(inputs), Variable(labels)\n",
    "        if if_use_gpu:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "        out = model(batch_x)\n",
    "        batch_y = batch_y.long()\n",
    "        loss = loss_func(out, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 返回每行元素最大值\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == batch_y).sum()\n",
    "        train_correct = train_correct.item()\n",
    "        train_loss = loss.item()\n",
    "        print('batch:{},Train Loss: {:.6f}, Acc: {:.6f}'.format(i+1,train_loss , train_correct /32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 57802752 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-c777571cf8cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0meval_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-c29383d7fd11>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-fe6608257d94>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 57802752 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation--------------------------------\n",
    "model.eval()\n",
    "eval_loss = 0.\n",
    "eval_acc = 0.\n",
    "\n",
    "for batch_x, batch_y in test_loader:\n",
    "    batch_x, batch_y = Variable(batch_x, requires_grad=False), Variable(batch_y, requires_grad=False)\n",
    "    if if_use_gpu:\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "    out = model(batch_x)\n",
    "    loss = loss_func(out, batch_y)\n",
    "    eval_loss += loss.item()\n",
    "    pred = torch.max(out, 1)[1]\n",
    "    num_correct = (pred == batch_y).sum()\n",
    "    eval_acc += num_correct.item()\n",
    "    \n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(test_data)), eval_acc / (len(test_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Early stopping (draft...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.delta = delta\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: %d / %d' % (self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=512, shuffle=True, num_workers=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def validation(net):\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    return valid_loss\n",
    "\n",
    "def train2(net, earlystopping=True):\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "    train_history = []\n",
    "    valid_history = []\n",
    "    estop = EarlyStopping(patience=2)\n",
    "    for epoch in range(30):\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        valid_loss = validation(net)\n",
    "        train_history.append(train_loss)\n",
    "        valid_history.append(valid_loss)\n",
    "        print('Epoch %02d: train loss %0.5f, validation loss %0.5f' % (epoch, train_loss, valid_loss))\n",
    "        estop.step(valid_loss)\n",
    "        if earlystopping and estop.early_stop:\n",
    "            break\n",
    "    return train_history, valid_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
