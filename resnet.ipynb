{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMlMf0NMU_AM"
   },
   "source": [
    "# Deep Residual Learning for Image Recognition\n",
    "\n",
    "Notebook written by Shuang HOU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvr6hAPGU_AP"
   },
   "source": [
    "At the end of 2015, Microsoft Research Asia released a paper titled [\"Deep Residual Learning for Image Recognition\" [1]](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), authored by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun. The paper achieved state-of-the-art results in Image classification and detection, winning the ImageNet and COCO competitions. This notebook is a PyTorch implementation of the Deep Residual Neural Networks (**ResNet** for short) based on this paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyKz7jWRU_AR"
   },
   "source": [
    "This notebook is prepared for students who have participated in the AML course (or a fairly close course). It supposes a basic knowledge of Deep Learning and Convolutional Neural Networks, which have been introduced in the previous courses ([DL](https://github.com/SupaeroDataScience/deep-learning/tree/main/deep), [CNN](https://github.com/fchouteau/isae-practical-deep-learning)), you can refer to them if needed.\n",
    "\n",
    "If you encounter any problems in the process of running this notebook, please feel free to contact me, I will help you solve the problem together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLMlRLAOU_AS"
   },
   "source": [
    "**Table of contents:**\n",
    "0. [Preparation](#sec0)\n",
    "1. [Dataset: Fashion-MNIST](#sec1)\n",
    "2. [Problem introduction](#sec2)\n",
    "3. [Construction of Residual Networks](#sec3)\n",
    "4. [Experiments](#sec4)\n",
    "5. [Conclusion](#sec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIk0oNrnU_AT"
   },
   "source": [
    "# <a id=\"sec0\"></a>0. Preparation\n",
    "\n",
    "In this notebook, we'll be using `torch` and `torchvision`, which we have already used in previous AML courses. Run the following code cells to install the necessary packages and verify that everything is working by importing everything. If it doesn't work, check the `requirements.txt` file and install the libraries manually using either `pip install` or `conda install`.\n",
    "\n",
    "Please refer to the [PyTorch](https://pytorch.org/get-started/locally/) website for installation instructions if necessary. We'll also be using packages `sklearn`, `numpy`, and `matplotlib`. \n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "Note that this notebook is fairly compute intensive and it might be better to **[run in Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true).**\n",
    "    \n",
    "If you use Colab, mind yourself to **add external folders** (especially solutions and img) to it, the data folder is not necessary to be added, because the data can be downloaded by running the code cell in part 1 Dataset. Then change alter default hardware CPU to **GPU**: just follow `Edit` > `Notebook settings` or `Runtime` > `Change runtime type` and select `GPU` as Hardware accelerator.\n",
    "       \n",
    "</div>\n",
    "\n",
    "<img src=\"img/runtime.png\" width=\"35%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LyVGdoasU_AU"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_SjP5f3RU_AV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as Data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7Rr5hJ7U_AV",
    "outputId": "bd8b0c8d-8e03-4a63-eb84-1785cae72f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.0+cu101\n",
      "Torchvision Version:  0.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oKK0vHLU_AW"
   },
   "source": [
    "# <a id=\"sec1\"></a>1. Dataset: Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmqVoNTSU_AW"
   },
   "source": [
    "[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28 $\\times$ 28 grayscale image, associated with a label from 10 classes. Fashion-MNIST is a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits but is more complex.\n",
    "\n",
    "<img src=\"img/fashion-mnist-small.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uyeFXiOxU_AX"
   },
   "outputs": [],
   "source": [
    "labels_text = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5n5HfH1U_AY"
   },
   "source": [
    "PyTorch comes with this dataset by default, but we need to download it. We'll then make dataloaders which lazily iterate through the datasets. We'll use a training set and a validation set and greatly reduce their sizes to make this notebook run in a reasonable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "szmFJ2KVU_AY"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter for DataLoader\n",
    "BATH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o0g3waDqU_AY"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "full_trainset = torchvision.datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
    "trainset, full_validset = torch.utils.data.random_split(full_trainset, (10000, 50000))\n",
    "validset, _ = torch.utils.data.random_split(full_validset, (1000, 49000))\n",
    "testset = torchvision.datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATH_SIZE, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=BATH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsYTk3OoU_AZ",
    "outputId": "fbf95cf0-2f28-42a2-d5ff-6328313de639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([512, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in trainloader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDP2UureU_Aa"
   },
   "source": [
    "# <a id=\"sec2\"></a>2. Problem introduction\n",
    "\n",
    "From experience, the depth of the network is crucial to the performance of the model. When the number of network layers is increased (increasing the depth), the network can extract more complex feature patterns, so theoretically, better results can be obtained when the model is deeper.\n",
    "\n",
    "But... Is learning better networks as easy as stacking more layers?\n",
    "\n",
    "Of course not! Deep network optimization is very difficult, and there will be many problems occurring, such as the notorious problem of [vanishing/exploding gradients [2]](https://ieeexplore-ieee-org.rev-doc.isae.fr/stamp/stamp.jsp?tp=&arnumber=279181). While these problems has been almost solved by methods such as [Normalized Initialization [3]](https://arxiv.org/pdf/1502.01852.pdf) and [Batch Normalization [4]](https://arxiv.org/pdf/1502.03167.pdf).\n",
    "\n",
    "However, experiments have found that when deeper networks are able to start converging, a degradation problem has been exposed. In other words, with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly. This phenomenon can be seen directly in Figure 1 from [paper[1]](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) which shows the training error (left) and test error (right) on CIFAR-10 with 20-layer and 56-layer \"plain\" networks. The deeper network has higher training error, and thus the same for test error. This is not caused by overfitting, because the training error (left) of the 56-layer network is also higher than that of the 20-layer.\n",
    "\n",
    "<img src=\"img/degradation.JPG\" width=\"60%\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 1. Training error (left) and test error (right) on CIFAR-10 with 20-layer and 56-layer \"plain\" networks.<br>\n",
    "    The deeper network has higher training error, and thus test error.</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CcavNkAU_Ab"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Let's think about this question:**<br>\n",
    "\n",
    "What caused the deeper network degradation problem?\n",
    "\n",
    "How to effectively solve the \"degradation\" problem caused by the increase in network depth?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXLOefISU_Ab"
   },
   "source": [
    "<div class=\"alert alert-info\"><a href=\"#answer1\" data-toggle=\"collapse\"><b>Ready to see the answer? (click to expand)</b></a><br>\n",
    "<div id=\"answer1\" class=\"collapse\">\n",
    "\n",
    "The problem of degradation is mainly due to the increase in network depth. During model training, the gradient cannot be effectively transmitted to the shallow network, resulting in vanishing/exploding gradients. Batch Normalization (BN) changes the data distribution by normalizing the output data, which is a forward process to solve the vanishing/exploding gradients problem. \n",
    "    \n",
    "For the degradation problem, instead of directly fitting a desired underlying mapping, it is better to make the network fitting a residual mapping. Here comes the Residual Network (ResNet)! ResNet directly connects the shallow network and the deep network by adding **shortcut connection** (Identity Map), so that the gradient can be well transmitted to the shallow layer.\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tK7xbymU_Ac"
   },
   "source": [
    "# <a id=\"sec3\"></a>3. Construction of Residual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQM7YkS6U_Ae"
   },
   "source": [
    "### <a id=\"sec3-1\"></a>3.1. Residual representation & shortcut connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n50T_4_JU_Ae"
   },
   "source": [
    "In response to the \"degradation\" problem, Kaiming He proposed a **deep residual learning framework**, which uses a multi-layer network to fit a residual mapping.\n",
    "\n",
    "Formally, denoting the desired underlying mapping as $H(x)$, we let the stacked nonlinear layers fit another mapping:\n",
    "\n",
    "$$F(x) := H(x)âˆ’x$$ \n",
    "\n",
    "The original mapping is recast into:\n",
    "\n",
    "$$F(x)+x$$. \n",
    "\n",
    "The formulation of $F(x)+x$ can be realized by feedforward neural networks with \"**shortcut connections**\". Shortcut connections are those skipping one or more layers. For the case in [paper [1]](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), the shortcut connections simply perform identity mapping, and their outputs are added to the outputs of the stacked layers. \n",
    "\n",
    "Figure 2 shows a 2-layer basic building block of residual learning in the deep residual networks:\n",
    "\n",
    "<img src=\"img/2-layer building block.JPG\" width=\"400px\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 2. Residual learning: a building block.</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ltCYHx4U_Ag"
   },
   "source": [
    "Why is easier to optimize the residual mapping than to optimize the original, unreferenced mapping?\n",
    "\n",
    "Formally, such a basic building block of ResNet can be expressed as:\n",
    "\n",
    "$$y_l = F(x_l,W_{l}) + x_l$$\n",
    "\n",
    "$$x_{l+1} = f(x_l)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x_l$ represents the input vector of the l-th residual block.\n",
    "- $x_{l+1}$ represents the output vector of the l-th residual block.\n",
    "- $F(x, W_l)$ represents the residual mapping to be learned, which is the superposition of multiple nonlinear convolutional layers.<br>\n",
    "  For the example in Figure 2 that has two layers, $F = W_2 \\sigma(W_1 x)$ in which $\\sigma$ represents the nonlinear activation function ReLU, and the biases are omitted for simplifying notations.\n",
    "- $F+x$ means shortcut connection, which corresponds to the addition of each pixel.\n",
    "- $f$ is an activation function.\n",
    "\n",
    "Then the learning representation from shallow to deep layer can be calculated as:\n",
    "\n",
    "$$X_L = x_l + \\sum_{i=l}^{L-1} F(x_i,W_{i}) $$\n",
    "\n",
    "According to the chain rule, the gradient of back propagation is:\n",
    "\n",
    "$$\\frac{\\partial loss}{\\partial x_l} = \\frac{\\partial loss}{\\partial x_L} Â· \\frac{\\partial x_L}{\\partial x_l} = \\frac{\\partial loss}{\\partial x_L} Â· \\left( 1+ \\frac{\\partial}{\\partial x_L}\\sum_{i=l}^{L-1} F(x_i,W_{i}) \\right)$$\n",
    "\n",
    "The $1$ in the parentheses indicates that the shortcut connection can spread the gradient without loss, and the other item (residual gradient) needs to pass through the layer with weights, thsu the gradient is not directly transferred. The residual gradient will not be so coincidentally that all are equal to -1, and even if it is relatively small, the existence of $1$ in the parentheses will not cause the gradient to disappear. So the residual learning will be easier than the original, unreferenced mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrH4AIbPU_Ai"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**In brief:**<br>\n",
    "- If identity mappings are added, a deeper network will not perform worse than a shallow network.\n",
    "- It is difficult to learn identify mapings in a network structure composed of multiple non-linear layers.\n",
    "- If identity mapings is the optimal link method, then the weight parameters of $F(x)$ will tend to $0$.\n",
    "- If the optimal mapping is close to identity mappings, it is much easier to find the $F(x)$ corresponding to the identity mappings (initial parameters near 0) during optimization than to approximately fit a completely new function.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzJqnCMpU_Aj"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Note 1:**<br>\n",
    "    \n",
    "Identity shortcut connections add neither extra parameter nor computational complexity. The entire network can still be trained end-to-end by SGD with backpropagation, and can be easily implemented using common libraries (e.g., [Caffe [5]](https://arxiv.org/pdf/1408.5093.pdf)) without modifying the solvers.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note 2:**<br>\n",
    "    \n",
    "In the expression above $y_l = F(x_l,W_{l}) + x_l$, the dimensions of $x_l$ and $F$ must be equal. If this is not the case (e.g., when changing the input/output channels), we can perform a linear projection $W_s$ by the shortcut connections to match the dimensions, which can be implemented with a convolutional layer in programming:\n",
    "\n",
    "$$y_l = F(x_l, W_l) + W_{s}x_l$$\n",
    "\n",
    "The meaning of the parameters in this formula is the same as before. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKbQ5IP0U_Ak"
   },
   "source": [
    "### <a id=\"sec3-2\"></a>3.2. Basic building block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvIJk1wsU_Ak"
   },
   "source": [
    "A basic 2-layer building block is consist of the following parts sequentially, as shown in Figure 3:\n",
    "\n",
    "- a first 3$\\times$3 convolution\n",
    "- a Batch Normalization \n",
    "- ReLU activation\n",
    "- a second 3$\\times$3 convolution\n",
    "- a Batch Normalization \n",
    "- Addition of the shortcut connection\n",
    "- ReLU activation\n",
    "\n",
    "<img src=\"img/basic-building-block.png\" width=\"200px\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 3. The specific composition of the 2-layer basic building block</font></center>\n",
    "\n",
    "Now we come to implement this building block in programming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UKmbf6dqU_Al"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channel, out_channel, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ljQkgM0yU_Al"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Basic building block for ResNet-18/34.\n",
    "    \n",
    "    Argsï¼š\n",
    "        - in_channel: Number of input channel\n",
    "        - out_channel: Number of output channel\n",
    "        - stride: Number of stride \n",
    "        - downsample: \"None\" for identity downsample, otherwise for a real downsample\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 1    # Record whether the number of convolution kernels in each layer has changed\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channel, out_channel, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channel, out_channel)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x    # Record the output of the last residual block\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:    # Determine if need to downsample for dimension matching\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTlFO003U_Am"
   },
   "source": [
    "### <a id=\"sec3-3\"></a>3.3. Deeper bottleneck building block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJqHl7BwU_Am"
   },
   "source": [
    "In terms of $F(x_l, W_l)$, it should not be limited to the 2-layer convolution connection mentioned above, it can be more diverse, 3 layers, or even more; but not 1 layer, because the performance of 1-layer will be unsatisfactory.\n",
    "\n",
    "A 3-layer building block is shown on the right of Figure 4, which called a **bottleneck** building block, and is used to build the ResNet-50/101/152.\n",
    "\n",
    "<img src=\"img/3-layer building block.JPG\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 4. Two different building blocks for residual learning.<br> \n",
    "    Left: a building block (on 56 $\\times$ 56 feature maps) as in Figure 6 for ResNet-34.<br>\n",
    "    Right: a \"bottleneck\" building block for ResNet-50/101/152.</font></center>\n",
    "    \n",
    "The purpose of such a bottleneck building block is to reduce the number of parameters. The first 1$\\times$1 convolution reduces the 256-dimensional channel to 64-dimensional, and then it is restored by 1$\\times$1 convolution at the end.\n",
    "\n",
    "The total number of parameters used in the bottleneck building block is: \n",
    "\n",
    "$$1\\times1\\times256\\times64 + 3\\times3\\times64\\times64 + 1\\times1\\times64\\times256 = 69632$$\n",
    "\n",
    "Without bottleneck, it is a convolution of two 3x3x256, the number of parameters is: \n",
    "\n",
    "$$3\\times3\\times256\\times256\\times2 = 1179648$$\n",
    "\n",
    "which is $16.94$ times the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-Ac7gocU_Am"
   },
   "source": [
    "The bottleneck building blocks used for ResNet-50/101/152 is shown in the Figure 5 below, composed of an identity block (skip connection) skipping over 3 layers, and a convolutional block used to adjust the dimensions.\n",
    "\n",
    "<img src=\"img/resnet50-identity-block.png\" width=\"70%\"></img>\n",
    "\n",
    "<img src=\"img/resnet50-conv-block.png\" width=\"70%\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 5. The bottleneck building blocks of ResNet-50/101/152</font></center>\n",
    "\n",
    "Now we come to implement this bottleneck building block in programming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pEHqp2wuU_An"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channel, out_channel, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=3,\n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_channel, out_channel, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FDz8bhFaU_An"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck building block for ResNet-50/101/152.\n",
    "    \n",
    "    Argsï¼š\n",
    "        - in_channel: Number of input channel\n",
    "        - out_channel: Number of output channel\n",
    "        - stride: Number of stride \n",
    "        - downsample: \"None\" for identity downsample, otherwise for a real downsample\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    expansion = 4       # The number of convolution kernels in the third layer (256, 512, 1024, 2048) \n",
    "                        # is 4 times the number of convolution kernels in the first or second layer (64, 128, 256, 512)\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(in_channel, out_channel)           # Squeeze channels for dimensionality reduce\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = conv3x3(out_channel, out_channel, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = conv1x1(out_channel, out_channel * self.expansion)   # Unsqueeze channels for dimensionality increase\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq2OTYTYU_An"
   },
   "source": [
    "### <a id=\"sec3-3\"></a>3.3. Complete network architectures\n",
    "\n",
    "On the right of the Figure 6 is a overall residual network with 34 parameter layers (ResNet-34). The dotted shortcuts increase dimensions. <br>\n",
    "Table 1 shows more details and other variants.\n",
    "\n",
    "<img src=\"img/plain-res nets.jpg\" width=\"55%\"></img>\n",
    "\n",
    "<center><font size=1.5><br>Figure 6. Example network architectures for ImageNet.<br>\n",
    "    Left: the [VGG-19] model(19.6 billion FLOPs) as a reference.<br> \n",
    "    Middle: a plain network with 34 parameter layers (3.6 billion FLOPs).<br>\n",
    "    Right: a residual network with 34 parameter layers (3.6 billionFLOPs).<br>\n",
    "    The dotted shortcuts increase dimensions.</font></center>\n",
    "\n",
    "<center><font size=1.5><br>Table 1. Architectures for ResNet-18/34 and ResNet-50/101/152.<br>\n",
    "    Building blocks are shown in brackets, with the numbers of blocks stacked.<br>\n",
    "    Downsampling is performed by conv3, conv4, and conv5 with a stride of 2.</font></center>\n",
    "    \n",
    "<img src=\"img/ResNet-architecture.JPG\" width=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG0HKcNSU_Ao"
   },
   "source": [
    "The building blocks of the same color can be considered as a large color-layer of the whole ResNet. For example, for the ResNet-34 and ResNet-50, the number of residual blocks in each color-layer are both: [3, 4, 6, 3] according to Table 1.\n",
    "\n",
    "Therefore, for **ResNet-34**, it is sequentially consist of:\n",
    "\n",
    "- conv1: a 3 x 3 convolution (+ maxpool)\n",
    "- conv2: **3** basic building block, output size = 56 x 56\n",
    "- conv3: **4** basic building block, output size = 28 x 28\n",
    "- conv4: **6** basic building block, output size = 14 x 14\n",
    "- conv5: **3** basic building block, output size = 7 x 7\n",
    "- avgpool + fc: output size = 1 x 1\n",
    "\n",
    "For ResNet-34, the number of layers of each residual block is **[3, 4, 6, 3]**.\n",
    "\n",
    "The total number of layers of ResNet-34 is: $1 + 2\\times(3+4+6+3) + 1 = 34$, so called ResNet-34."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFWtw_cgU_Ao"
   },
   "source": [
    "Similar for **ResNet-50**, except changing the 2-layer basic building block to a 3-layer bottleneck building block:\n",
    "\n",
    "- conv1: a 3 x 3 convolution (+ maxpool)\n",
    "- conv2: **3** bottleneck building block, output size = 56 x 56\n",
    "- conv3: **4** bottleneck building block, output size = 28 x 28\n",
    "- conv4: **6** bottleneck building block, output size = 14 x 14\n",
    "- conv5: **3** bottleneck building block, output size = 7 x 7\n",
    "- avgpool + fc: output size = 1 x 1\n",
    "\n",
    "For ResNet-50, the number of layers of each residual block is the same as ResNet-34 : **[3, 4, 6, 3]**.\n",
    "\n",
    "The total number of layers of ResNet-50 is: $1 + 3\\times(3+4+6+3) + 1 = 50$, so called ResNet-50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPrLQQBAU_Ao"
   },
   "source": [
    "**ResNet-101** has the same bettleneck building block as ResNet-50, but with a different layer numbers.\n",
    "\n",
    "- conv1: a 3 x 3 convolution (+ maxpool)\n",
    "- conv2: **3** bottleneck building block, output size = 56 x 56\n",
    "- conv3: **4** bottleneck building block, output size = 28 x 28\n",
    "- conv4: **23** bottleneck building block, output size = 14 x 14\n",
    "- conv5: **3** bottleneck building block, output size = 7 x 7\n",
    "- avgpool + fc: output size = 1 x 1\n",
    "\n",
    "For ResNet-101, the number of layers of each residual block is **[3, 4, 23, 3]**.\n",
    "\n",
    "The total number of layers of ResNet-101 is: $1 + 3\\times(3+4+23+3) + 1 = 101$, so called ResNet-101."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1Cwg1m9U_Ap"
   },
   "source": [
    "Now that we have previously defined the two different building blocks, let's implement the complete residual networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gPZ0XLEQU_Ap"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of ResNet architecture.\n",
    "    \n",
    "    Argï¼š\n",
    "        - block: \"BasicBlock\" for ResNet-18/34, \"Bottleneck\" for ResNet-50/101/152\n",
    "        - layers: The number of each residual layer, for example, [3,4,6,3] for the ResNet-34/50\n",
    "        - num_classes: The number of labels in the data set\n",
    "        - grayscale: \"True\" for single-channel images, \"False\" for 3-channel images\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.in_channel = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        #  conv1 + maxpooling\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #  conv2,3,4,5\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        #  avgpooling + fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        #  Initialization of the convolutional layer\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, out_channel, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != out_channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, out_channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel, out_channel, stride, downsample))\n",
    "        self.in_channel = out_channel * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_channel, out_channel))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fqiUCn_nU_Ap"
   },
   "outputs": [],
   "source": [
    "def resnet34(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    net = ResNet(block = BasicBlock,\n",
    "                 layers = [3, 4, 6, 3],\n",
    "                 num_classes = num_classes,\n",
    "                 grayscale = grayscale)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RGU8m5LPU_Aq"
   },
   "outputs": [],
   "source": [
    "def resnet50(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-50 model.\"\"\"\n",
    "    net = ResNet(block = Bottleneck,\n",
    "                 layers = [3, 4, 6, 3],\n",
    "                 num_classes = num_classes,\n",
    "                 grayscale = grayscale)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Gij3WnsU_Ar"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Now it's your turn!**\n",
    "<br>    \n",
    "Exercise 1: Known that **ResNet-18** has the same basic building block as ResNet-34, but for ResNet-18, the number of color-layers of each block is: **[2, 2, 2, 2]**, try to construct a function for resnet18.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vkViAqCfU_As"
   },
   "outputs": [],
   "source": [
    "# %load solutions/resnet18.py\n",
    "def resnet18(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwAtdSeHU_As"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Exercise 2: **ResNet-101** has the same bottleneck building block as ResNet-50, but for ResNet-101, the number of color-layers is: **[3, 4, 23, 3]**, try to construct a function for resnet101.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gObKW0EWU_As"
   },
   "outputs": [],
   "source": [
    "# %load solutions/resnet101.py\n",
    "def resnet101(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHRw1zGPU_At"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Exercise 3: **ResNet-152** has the same bottleneck building block as ResNet-50, but with the number of color-layers: **[3, 8, 36, 3]**, try to construct a function for resnet152.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Knhxs7rfU_At"
   },
   "outputs": [],
   "source": [
    "# %load solutions/resnet152.py\n",
    "def resnet152(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-152 model.\"\"\"\n",
    "    ### WRITE YOUR CODE HERE\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCimv2osU_At"
   },
   "source": [
    "# <a id=\"sec4\"></a>4. Experiments\n",
    "\n",
    "At the beginning of the experiment, there are some preparatory works to do:\n",
    "\n",
    "- Set up the device, the GPU is preferred because the calculation is very resource-intensive.\n",
    "- Setting global hyperparameters, which can be used for possible parameter tuning.\n",
    "- Model instantiation, for ResNet-34, ResNet-50 and ResNet101.\n",
    "\n",
    "In this part of experiments, we will conduct a comparative analysis of the model performance for ResNet-34, ResNet-50 and ResNet-101, because they are currently the three most commonly used residual network structures, and they have comparable meanings with each other: ResNet-34 and ResNet-50 have the same number of residual network layers [3, 4, 6, 3], ResNet-50 and ResNet-101 have the same bottleneck building blocks. We will successively experiment these three ResNet models respectively for model training, verification, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4512ZEKU_At",
    "outputId": "36aa5c0f-a64d-40d3-8e9d-64aa42393782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set up the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Training on {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iRiIZpPRU_Au"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 32*32\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "GRAYSCALE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sR0PF14U_Au"
   },
   "source": [
    "Run the following three cells to instantiate the model ResNet-34, ResNet-50 and ResNet-101 respectively, and for each ResNet, the specific composition of each layer will be displayed for viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpClETZ0U_Au",
    "outputId": "9215561a-dd30-4232-b8ed-4488cf76b8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net34 = resnet34(NUM_CLASSES, GRAYSCALE)\n",
    "net34 = net34.to(device)\n",
    "print(net34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aM01p3EkU_Au",
    "outputId": "be2c5de0-c996-4d19-fcf7-454b1585c4bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net50 = resnet50(NUM_CLASSES, GRAYSCALE)\n",
    "net50 = net50.to(device)\n",
    "print(net50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTfHuhJgU_Av",
    "outputId": "5d57dda0-a007-4a43-9d8a-d3fabe5d966a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net101 = resnet101(NUM_CLASSES, GRAYSCALE)\n",
    "net101 = net101.to(device)\n",
    "print(net101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NeUDk-1U_Av"
   },
   "source": [
    "### <a id=\"sec4-1\"></a>4.1.  Model training for three ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJLxzssiU_Av"
   },
   "source": [
    "`Torch` provides loss functions and optimizers that we can use instead of writing our own. For now, we'll use the `torch.nn.CrossEntropyLoss` and `torch.optim.SGD` functions. Another alternative optimizer function is `torch.optim.Adam`. If you want, you can also change the comment line of the optimizer in the following code cells to see how the result will change.\n",
    "\n",
    "Let's first look at the loss when the model is trained for only **one epoch**. The hyperparameter `NUM_EPOCHS` has not been used in this part, and there is no loop about epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2uPTxgMbU_Aw"
   },
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    # optimizer = torch.optim.Adam(net.parameters())       # Alternative optimizer \"Adam\"\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njaR0bb1U_Aw",
    "outputId": "b060369c-5c8e-4261-9f2b-1bc713b49217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 s, sys: 1.52 s, total: 4.24 s\n",
      "Wall time: 4.54 s\n",
      "train loss of ResNet-34 : 40.15110\n"
     ]
    }
   ],
   "source": [
    "%time train_loss_34 = train(net34)\n",
    "print('train loss of ResNet-34 : %0.5f' % (train_loss_34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmyLqUGNU_Aw",
    "outputId": "b389d043-ea63-4422-84cc-86d720a3079a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 s, sys: 3.26 s, total: 7.97 s\n",
      "Wall time: 8.3 s\n",
      "train loss of ResNet-50 : 49.03495\n"
     ]
    }
   ],
   "source": [
    "%time train_loss_50 = train(net50)\n",
    "print('train loss of ResNet-50 : %0.5f' % (train_loss_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TilpDjHU_Ax",
    "outputId": "75350f0c-70fb-4df0-a413-3d8f812a41ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.25 s, sys: 4.28 s, total: 10.5 s\n",
      "Wall time: 10.9 s\n",
      "train loss of ResNet-101 : 48.15834\n"
     ]
    }
   ],
   "source": [
    "%time train_loss_101 = train(net101)\n",
    "print('train loss of ResNet-101 : %0.5f' % (train_loss_101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVGp1Ht_U_Ax"
   },
   "source": [
    "From the perspective of train loss, that of a single epoch is still quite large.\n",
    "\n",
    "To see how our network performs more preciously, we'll apply it to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iKAMYwEQU_Ax"
   },
   "outputs": [],
   "source": [
    "def get_valid_predictions(net):\n",
    "    all_labels = np.array([])\n",
    "    predictions = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels = np.append(all_labels, labels.cpu().numpy())\n",
    "            predictions = np.append(predictions, predicted.cpu().numpy())\n",
    "    return all_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-SSOCYR9U_Ax"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Cg32lW-U_Ay",
    "outputId": "d692c472-2cdd-460f-d812-af4d31e079e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-34 accuracy:  0.602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.61      0.57      0.59       112\n",
      "     Trouser       0.87      0.83      0.85       109\n",
      "    Pullover       0.32      0.55      0.41        67\n",
      "       Dress       0.57      0.63      0.60        86\n",
      "        Coat       0.59      0.41      0.49       147\n",
      "      Sandal       0.57      0.49      0.53        87\n",
      "       Shirt       0.28      0.32      0.30        97\n",
      "     Sneaker       0.78      0.66      0.72       104\n",
      "         Bag       0.62      0.84      0.71        82\n",
      "  Ankle boot       0.90      0.76      0.83       109\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.61      0.61      0.60      1000\n",
      "weighted avg       0.63      0.60      0.61      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_valid_34, predictions_34 = get_valid_predictions(net34)\n",
    "\n",
    "print('ResNet-34 accuracy: ', accuracy_score(predictions_34, y_valid_34))\n",
    "print(classification_report(predictions_34, y_valid_34, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqTJjWLkU_Ay",
    "outputId": "7c7b50d7-68d3-4107-cc7e-7f254a66ece3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-50 accuracy:  0.19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.13      0.16      0.15        88\n",
      "     Trouser       0.30      0.21      0.24       151\n",
      "    Pullover       0.13      0.22      0.16        69\n",
      "       Dress       0.19      0.25      0.22        72\n",
      "        Coat       0.15      0.19      0.17        85\n",
      "      Sandal       0.04      0.07      0.05        45\n",
      "       Shirt       0.12      0.11      0.12       114\n",
      "     Sneaker       0.16      0.25      0.20        55\n",
      "         Bag       0.23      0.16      0.19       160\n",
      "  Ankle boot       0.43      0.25      0.32       161\n",
      "\n",
      "    accuracy                           0.19      1000\n",
      "   macro avg       0.19      0.19      0.18      1000\n",
      "weighted avg       0.22      0.19      0.20      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_valid_50, predictions_50 = get_valid_predictions(net50)\n",
    "\n",
    "print('ResNet-50 accuracy: ', accuracy_score(predictions_50, y_valid_50))\n",
    "print(classification_report(predictions_50, y_valid_50, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kD2DSs9U_Ay",
    "outputId": "0292994b-7bdf-4fa7-b455-8fe9f5fe9f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-101 accuracy:  0.181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.17      0.19      0.18        95\n",
      "     Trouser       0.21      0.54      0.30        41\n",
      "    Pullover       0.14      0.14      0.14       117\n",
      "       Dress       0.11      0.28      0.15        36\n",
      "        Coat       0.15      0.18      0.16        90\n",
      "      Sandal       0.37      0.18      0.24       158\n",
      "       Shirt       0.20      0.16      0.18       139\n",
      "     Sneaker       0.23      0.18      0.20       112\n",
      "         Bag       0.13      0.16      0.15        94\n",
      "  Ankle boot       0.15      0.12      0.13       118\n",
      "\n",
      "    accuracy                           0.18      1000\n",
      "   macro avg       0.19      0.21      0.18      1000\n",
      "weighted avg       0.20      0.18      0.18      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_valid_101, predictions_101 = get_valid_predictions(net101)\n",
    "\n",
    "print('ResNet-101 accuracy: ', accuracy_score(predictions_101, y_valid_101))\n",
    "print(classification_report(predictions_101, y_valid_101, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZMVczsmU_Ay"
   },
   "source": [
    "From the perspective of ResNet model prediction accuracy, that of a single epoch for all the three ResNet models are unsatisfactory. Theoretically known that the accuracy of training results will improve as the number of training epochs increases.\n",
    "\n",
    "Here comes a hyperparameter `NUM_EPOCHS` that we set previously, which indicates how many epochs will be trained. Its initial value is set to 50, you can try to modify the value of this hyperparameter to see how the result will change if you want. But be aware that the larger the value of `NUM_EPOCHS`, the longer the calculation will take.\n",
    "\n",
    "Now, Let's train our model net34, net50 and net101 completely with **`NUM_EPOCHS`** times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "R4lS7U7JU_Ay"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def validation(net):\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    return valid_loss\n",
    "\n",
    "def train_all(net):\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "    # optimizer = torch.optim.Adam(net.parameters())      # Alternative optimizer \"Adam\"\n",
    "    train_history = []\n",
    "    valid_history = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        valid_loss = validation(net)\n",
    "        train_history.append(train_loss)\n",
    "        valid_history.append(valid_loss)\n",
    "        print('Epoch %02d: train loss %0.5f, validation loss %0.5f' % (epoch, train_loss, valid_loss))\n",
    "    return train_history, valid_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OREyF0oiU_Az"
   },
   "source": [
    "The training of the ResNet model will take a few minutes depending on the processor. For reference, running on the GPU in my laptop, with `NUM_EPOCHS`=50, ResNet-34 takes about 4 minutes,  ResNet-50 takes about 7 minutes, and ResNet-101 takes about 10 minutes. It will take longer to run on the CPU, that is why it is recommended to run this notebook in Google Colab.\n",
    "\n",
    "Hope that it will take shorter time to run on your side, maybe you can take this opportunity to have a coffee break ;-)  But don't forget to run the following six code cells of model training before going for a coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVPLS9cgU_Az",
    "outputId": "3e00e392-c589-4997-90f3-9b43e1640d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00: train loss 106.03732, validation loss 3.64067\n",
      "Epoch 01: train loss 29.96314, validation loss 2.23967\n",
      "Epoch 02: train loss 19.34668, validation loss 1.82376\n",
      "Epoch 03: train loss 16.69749, validation loss 1.54463\n",
      "Epoch 04: train loss 13.77235, validation loss 1.37090\n",
      "Epoch 05: train loss 12.58052, validation loss 1.31411\n",
      "Epoch 06: train loss 11.56787, validation loss 1.21249\n",
      "Epoch 07: train loss 10.83895, validation loss 1.21739\n",
      "Epoch 08: train loss 10.33804, validation loss 1.10972\n",
      "Epoch 09: train loss 9.75424, validation loss 1.07066\n",
      "Epoch 10: train loss 9.18258, validation loss 1.09703\n",
      "Epoch 11: train loss 8.62650, validation loss 1.06962\n",
      "Epoch 12: train loss 8.19472, validation loss 1.04120\n",
      "Epoch 13: train loss 7.75173, validation loss 0.96505\n",
      "Epoch 14: train loss 7.36269, validation loss 0.96841\n",
      "Epoch 15: train loss 6.71230, validation loss 0.92811\n",
      "Epoch 16: train loss 6.64439, validation loss 0.94405\n",
      "Epoch 17: train loss 6.43581, validation loss 1.03403\n",
      "Epoch 18: train loss 6.00701, validation loss 0.93162\n",
      "Epoch 19: train loss 6.12624, validation loss 0.84613\n",
      "Epoch 20: train loss 5.30521, validation loss 0.94559\n",
      "Epoch 21: train loss 4.98533, validation loss 0.99421\n",
      "Epoch 22: train loss 4.70944, validation loss 0.87976\n",
      "Epoch 23: train loss 4.71063, validation loss 0.93443\n",
      "Epoch 24: train loss 4.68532, validation loss 0.86367\n",
      "Epoch 25: train loss 4.08439, validation loss 0.84776\n",
      "Epoch 26: train loss 3.76946, validation loss 0.92921\n",
      "Epoch 27: train loss 3.88536, validation loss 0.96317\n",
      "Epoch 28: train loss 3.38322, validation loss 0.89442\n",
      "Epoch 29: train loss 3.44234, validation loss 0.87838\n",
      "Epoch 30: train loss 3.30507, validation loss 1.01566\n",
      "Epoch 31: train loss 3.32195, validation loss 0.93252\n",
      "Epoch 32: train loss 3.20608, validation loss 0.92479\n",
      "Epoch 33: train loss 2.35750, validation loss 1.05858\n",
      "Epoch 34: train loss 3.20814, validation loss 0.95650\n",
      "Epoch 35: train loss 2.51930, validation loss 1.09630\n",
      "Epoch 36: train loss 2.21378, validation loss 0.98653\n",
      "Epoch 37: train loss 1.94525, validation loss 1.20969\n",
      "Epoch 38: train loss 1.81479, validation loss 1.19498\n",
      "Epoch 39: train loss 2.38891, validation loss 1.16203\n",
      "Epoch 40: train loss 2.78975, validation loss 1.01675\n",
      "Epoch 41: train loss 1.75792, validation loss 1.09940\n",
      "Epoch 42: train loss 1.25424, validation loss 1.23638\n",
      "Epoch 43: train loss 1.21916, validation loss 1.21818\n",
      "Epoch 44: train loss 1.07360, validation loss 1.36094\n",
      "Epoch 45: train loss 1.44266, validation loss 1.42581\n",
      "Epoch 46: train loss 1.74746, validation loss 1.22139\n",
      "Epoch 47: train loss 1.41041, validation loss 1.26366\n",
      "Epoch 48: train loss 1.00504, validation loss 1.36662\n",
      "Epoch 49: train loss 1.09598, validation loss 1.39736\n",
      "total time for ResNet-34: 259.47122740745544 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_history_34, valid_history_34 = train_all(net34)\n",
    "end = time.time()\n",
    "print(f'total time for ResNet-34: {end - start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YG_wMMltU_Az"
   },
   "outputs": [],
   "source": [
    "# Save trained model for later use\n",
    "model_file_34 = \"models/resnet34\"   \n",
    "torch.save(net34, model_file_34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you get this error when running the code above for model saving:\n",
    "    \n",
    "    `FileNotFoundError: [Errno 2] No such file or directory: 'models/resnet34'`\n",
    "    \n",
    "Don't worry, this is for the raison that we don't have the `models` folder yet.\n",
    "    \n",
    "Please manually create a `models` folder at the same level as `resnet.ipynb`, and then run the code again.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyZFeMhoU_Az",
    "outputId": "7bdbadd5-c9f8-4fd4-9ebc-049433de8466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00: train loss 242.25215, validation loss 4.50700\n",
      "Epoch 01: train loss 44.66379, validation loss 4.44224\n",
      "Epoch 02: train loss 44.11992, validation loss 4.45448\n",
      "Epoch 03: train loss 43.81619, validation loss 4.40447\n",
      "Epoch 04: train loss 43.68646, validation loss 4.40462\n",
      "Epoch 05: train loss 43.05862, validation loss 4.33753\n",
      "Epoch 06: train loss 42.69764, validation loss 4.34281\n",
      "Epoch 07: train loss 41.98406, validation loss 4.19080\n",
      "Epoch 08: train loss 40.10318, validation loss 3.89935\n",
      "Epoch 09: train loss 38.46389, validation loss 3.68492\n",
      "Epoch 10: train loss 35.12775, validation loss 3.21457\n",
      "Epoch 11: train loss 29.31037, validation loss 2.79990\n",
      "Epoch 12: train loss 25.43008, validation loss 2.50542\n",
      "Epoch 13: train loss 22.94154, validation loss 2.33957\n",
      "Epoch 14: train loss 21.14796, validation loss 2.14664\n",
      "Epoch 15: train loss 19.85869, validation loss 2.39080\n",
      "Epoch 16: train loss 19.17495, validation loss 1.87019\n",
      "Epoch 17: train loss 18.31631, validation loss 1.95705\n",
      "Epoch 18: train loss 18.73210, validation loss 2.17670\n",
      "Epoch 19: train loss 17.26920, validation loss 1.88756\n",
      "Epoch 20: train loss 16.16441, validation loss 1.82676\n",
      "Epoch 21: train loss 16.19204, validation loss 1.98700\n",
      "Epoch 22: train loss 17.03456, validation loss 1.70826\n",
      "Epoch 23: train loss 16.83121, validation loss 1.77825\n",
      "Epoch 24: train loss 15.30285, validation loss 1.70037\n",
      "Epoch 25: train loss 14.79605, validation loss 1.66257\n",
      "Epoch 26: train loss 14.80497, validation loss 2.06878\n",
      "Epoch 27: train loss 14.32114, validation loss 1.72550\n",
      "Epoch 28: train loss 14.60450, validation loss 2.08186\n",
      "Epoch 29: train loss 14.37498, validation loss 1.70200\n",
      "Epoch 30: train loss 12.96209, validation loss 1.53366\n",
      "Epoch 31: train loss 13.62721, validation loss 2.01480\n",
      "Epoch 32: train loss 12.93977, validation loss 1.60934\n",
      "Epoch 33: train loss 13.70625, validation loss 1.59324\n",
      "Epoch 34: train loss 13.41657, validation loss 1.51926\n",
      "Epoch 35: train loss 13.26360, validation loss 1.46505\n",
      "Epoch 36: train loss 11.57944, validation loss 1.38201\n",
      "Epoch 37: train loss 12.35116, validation loss 1.83232\n",
      "Epoch 38: train loss 11.26571, validation loss 1.62347\n",
      "Epoch 39: train loss 10.06946, validation loss 1.34111\n",
      "Epoch 40: train loss 9.03385, validation loss 1.28244\n",
      "Epoch 41: train loss 9.18799, validation loss 1.52329\n",
      "Epoch 42: train loss 9.42552, validation loss 1.42869\n",
      "Epoch 43: train loss 9.60184, validation loss 1.40188\n",
      "Epoch 44: train loss 8.26438, validation loss 1.42029\n",
      "Epoch 45: train loss 7.52138, validation loss 1.35894\n",
      "Epoch 46: train loss 7.60868, validation loss 1.31560\n",
      "Epoch 47: train loss 7.73012, validation loss 1.19661\n",
      "Epoch 48: train loss 8.74156, validation loss 1.39223\n",
      "Epoch 49: train loss 7.61884, validation loss 1.23226\n",
      "total time for ResNet-50: 458.8185613155365 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_history_50, valid_history_50 = train_all(net50)\n",
    "end = time.time()\n",
    "print(f'total time for ResNet-50: {end - start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "QH5d0Df6U_A0"
   },
   "outputs": [],
   "source": [
    "model_file_50 = \"models/resnet50\"\n",
    "torch.save(net50, model_file_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhQGGdNrU_A0",
    "outputId": "5424a5e1-5756-43b9-d31d-55b3465eceba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00: train loss 213.83583, validation loss 4.45988\n",
      "Epoch 01: train loss 44.73706, validation loss 4.39519\n",
      "Epoch 02: train loss 44.16062, validation loss 4.38512\n",
      "Epoch 03: train loss 42.99606, validation loss 4.11176\n",
      "Epoch 04: train loss 39.44299, validation loss 3.70863\n",
      "Epoch 05: train loss 35.91057, validation loss 3.42217\n",
      "Epoch 06: train loss 33.01411, validation loss 3.24951\n",
      "Epoch 07: train loss 29.21136, validation loss 2.72464\n",
      "Epoch 08: train loss 26.27216, validation loss 2.63650\n",
      "Epoch 09: train loss 24.59198, validation loss 2.34664\n",
      "Epoch 10: train loss 23.77019, validation loss 2.38384\n",
      "Epoch 11: train loss 21.86389, validation loss 2.14144\n",
      "Epoch 12: train loss 19.88868, validation loss 1.97442\n",
      "Epoch 13: train loss 19.32452, validation loss 1.87287\n",
      "Epoch 14: train loss 18.62483, validation loss 2.00889\n",
      "Epoch 15: train loss 17.93157, validation loss 1.74627\n",
      "Epoch 16: train loss 18.95081, validation loss 1.92702\n",
      "Epoch 17: train loss 17.90167, validation loss 1.96143\n",
      "Epoch 18: train loss 16.36273, validation loss 1.65556\n",
      "Epoch 19: train loss 16.19382, validation loss 1.65922\n",
      "Epoch 20: train loss 15.45020, validation loss 1.67795\n",
      "Epoch 21: train loss 14.86357, validation loss 1.57412\n",
      "Epoch 22: train loss 14.59415, validation loss 1.50231\n",
      "Epoch 23: train loss 14.42444, validation loss 1.55528\n",
      "Epoch 24: train loss 14.34375, validation loss 1.48275\n",
      "Epoch 25: train loss 13.61497, validation loss 1.48600\n",
      "Epoch 26: train loss 14.05521, validation loss 1.48419\n",
      "Epoch 27: train loss 13.62298, validation loss 1.43542\n",
      "Epoch 28: train loss 13.13303, validation loss 1.42817\n",
      "Epoch 29: train loss 13.16441, validation loss 1.36079\n",
      "Epoch 30: train loss 12.62460, validation loss 1.33942\n",
      "Epoch 31: train loss 12.13395, validation loss 1.34005\n",
      "Epoch 32: train loss 12.21028, validation loss 1.32312\n",
      "Epoch 33: train loss 11.55449, validation loss 1.26949\n",
      "Epoch 34: train loss 11.22559, validation loss 1.26689\n",
      "Epoch 35: train loss 10.40558, validation loss 1.29268\n",
      "Epoch 36: train loss 10.52490, validation loss 1.22995\n",
      "Epoch 37: train loss 10.11092, validation loss 1.18667\n",
      "Epoch 38: train loss 9.86612, validation loss 1.16533\n",
      "Epoch 39: train loss 9.40071, validation loss 1.09059\n",
      "Epoch 40: train loss 8.98113, validation loss 1.13552\n",
      "Epoch 41: train loss 8.64465, validation loss 1.10112\n",
      "Epoch 42: train loss 9.50260, validation loss 1.25691\n",
      "Epoch 43: train loss 10.05811, validation loss 1.10641\n",
      "Epoch 44: train loss 8.69274, validation loss 1.01366\n",
      "Epoch 45: train loss 7.98112, validation loss 0.94978\n",
      "Epoch 46: train loss 7.38950, validation loss 0.98947\n",
      "Epoch 47: train loss 7.18714, validation loss 1.03247\n",
      "Epoch 48: train loss 7.28541, validation loss 1.06246\n",
      "Epoch 49: train loss 7.41126, validation loss 0.94594\n",
      "total time for ResNet-101: 590.6229286193848 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_history_101, valid_history_101 = train_all(net101)\n",
    "end = time.time()\n",
    "print(f'total time for ResNet-101: {end - start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "IyDGvkVOU_A0"
   },
   "outputs": [],
   "source": [
    "model_file_101 = \"models/resnet101\"\n",
    "torch.save(net101, model_file_101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNatjcmTU_A0"
   },
   "source": [
    "During the training process, the training loss and validation loss of each epoch are saved in the history record and are returned by the function. \n",
    "\n",
    "Let's take a look at these losses more intuitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "REnpRoMGU_A1"
   },
   "outputs": [],
   "source": [
    "def plot_train_val(train, valid):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.set_ylabel('Training', color=color)\n",
    "    ax1.plot(train, color=color)\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Validation', color=color)\n",
    "    ax2.plot(valid, color=color)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "grk61A0CU_A1",
    "outputId": "b4e56f6b-f91e-4262-e718-a20fd6a8d88d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val(train_history_34, valid_history_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "atnxKbuAU_A1",
    "outputId": "e71d35bf-4ad5-4109-b19f-03766e58e808"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val(train_history_50, valid_history_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "jNIUf5GnU_A1",
    "outputId": "c73e4b34-4c77-4305-b73a-952f26af0698"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val(train_history_101, valid_history_101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hS6RvQbQU_A2"
   },
   "source": [
    "As we see in the above plots, for all these three ResNets, they all have a common phenomenon: the validation loss might fluctuate or increase while minimizing the training loss. This is considered to be caused by overfitting to the training data, which can be solved by some methods practiced in our previous [deep learning courses](https://github.com/SupaeroDataScience/deep-learning/tree/main/deep), such as: Early stopping, change of the optimizer, and Dropout. Due to limited time, we will not do more experiments about overfitting here, but you can try these methods after class if you want.\n",
    "\n",
    "Now let's take a quantitative look at the prediction accuracy of the three residual networks on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4NhRZZGU_A2",
    "outputId": "d0437baf-675b-4e0e-8fa3-45eacdee93b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-34 Accuracy:  0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.82      0.75      0.79       114\n",
      "     Trouser       0.97      1.00      0.99       102\n",
      "    Pullover       0.71      0.82      0.76       100\n",
      "       Dress       0.86      0.89      0.88        91\n",
      "        Coat       0.86      0.76      0.81       117\n",
      "      Sandal       0.95      0.97      0.96        73\n",
      "       Shirt       0.64      0.67      0.65       105\n",
      "     Sneaker       0.97      0.89      0.93        95\n",
      "         Bag       0.96      0.93      0.95       116\n",
      "  Ankle boot       0.93      0.99      0.96        87\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.87      0.87      0.87      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you have saved the trained model before, then uncomment the first line\n",
    "# and you can download the trained model from the `models/` folder.\n",
    "\n",
    "# net34 = torch.load(\"models/resnet34\")\n",
    "\n",
    "y_valid_34, predictions_34 = get_valid_predictions(net34)\n",
    "\n",
    "print('ResNet-34 Accuracy: ', accuracy_score(predictions_34, y_valid_34))\n",
    "print(classification_report(predictions_34, y_valid_34, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msTwC7PKU_A2",
    "outputId": "dc19856b-72c2-4084-ced3-70ba08197dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-50 Accuracy:  0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.78      0.68      0.73       121\n",
      "     Trouser       0.91      0.99      0.95        97\n",
      "    Pullover       0.79      0.70      0.74       130\n",
      "       Dress       0.79      0.83      0.81        89\n",
      "        Coat       0.81      0.66      0.73       127\n",
      "      Sandal       0.92      0.95      0.93        73\n",
      "       Shirt       0.33      0.58      0.42        62\n",
      "     Sneaker       0.98      0.88      0.92        98\n",
      "         Bag       0.95      0.91      0.93       116\n",
      "  Ankle boot       0.93      0.99      0.96        87\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.82      0.81      1000\n",
      "weighted avg       0.83      0.81      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# net50 = torch.load(\"models/resnet50\")\n",
    "\n",
    "y_valid_50, predictions_50 = get_valid_predictions(net50)\n",
    "\n",
    "print('ResNet-50 Accuracy: ', accuracy_score(predictions_50, y_valid_50))\n",
    "print(classification_report(predictions_50, y_valid_50, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIV5YVe6U_A2",
    "outputId": "f1a59ddb-8947-48d5-aca2-bcc410f41246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-101 Accuracy:  0.841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.86      0.72      0.78       125\n",
      "     Trouser       0.94      1.00      0.97        99\n",
      "    Pullover       0.74      0.83      0.78       103\n",
      "       Dress       0.87      0.77      0.82       106\n",
      "        Coat       0.83      0.66      0.74       130\n",
      "      Sandal       0.93      0.96      0.95        73\n",
      "       Shirt       0.44      0.69      0.53        70\n",
      "     Sneaker       0.97      0.91      0.94        93\n",
      "         Bag       0.96      0.97      0.96       110\n",
      "  Ankle boot       0.97      0.98      0.97        91\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.85      0.85      0.84      1000\n",
      "weighted avg       0.86      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# net101 = torch.load(\"models/resnet101\")\n",
    "\n",
    "y_valid_101, predictions_101 = get_valid_predictions(net101)\n",
    "\n",
    "print('ResNet-101 Accuracy: ', accuracy_score(predictions_101, y_valid_101))\n",
    "print(classification_report(predictions_101, y_valid_101, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfL7GYeWU_A2"
   },
   "source": [
    "The results show that all the three ResNets show good performance. In the case of 50 epochs, the prediction accuracy of all the three exceeded 80%, even close to 90%. If we further increase the number of epochs `NUM_EPOCHS`, or choose a deeper residual network structure such as ResNet-152, the result will definitely be better according to the [paper [1]](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf). However, with the network depth and the number of epochs increase, the time required for model training will be longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynn8g4OQU_A3"
   },
   "source": [
    "### <a id=\"sec4-2\"></a>4.2.  Test for three ResNets\n",
    "\n",
    "We'll test the performance of the three trained residual networks ResNet-34, ResNet-50 and ResNet-101 on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "dGM_GiABU_A3"
   },
   "outputs": [],
   "source": [
    "def run_test(net):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        pred = []\n",
    "        all_label = []\n",
    "        for batch_idx, (data, label) in enumerate(testloader):\n",
    "            batch_x, batch_y = data.to(device), label.to(device)\n",
    "            batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "            output = net(batch_x)\n",
    "            \n",
    "            pred2 = output.max(1, keepdim=True)[1]\n",
    "            pred2 = pred2.cpu().numpy()  \n",
    "            for ii in range(len(pred2)):\n",
    "                pred.append((pred2[ii])[0])\n",
    "            all_label = np.append(all_label, batch_y.cpu().numpy())\n",
    "\n",
    "    return pred, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyAtDf-tU_A3",
    "outputId": "5426877b-e203-437e-c38c-2372805fbd5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-34 Accuracy:  0.8531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.79      0.80      0.79       991\n",
      "     Trouser       0.97      0.99      0.98       981\n",
      "    Pullover       0.67      0.84      0.75       792\n",
      "       Dress       0.83      0.89      0.86       930\n",
      "        Coat       0.89      0.69      0.78      1285\n",
      "      Sandal       0.92      0.98      0.95       940\n",
      "       Shirt       0.61      0.60      0.61      1011\n",
      "     Sneaker       0.99      0.87      0.92      1138\n",
      "         Bag       0.96      0.96      0.96       999\n",
      "  Ankle boot       0.91      0.98      0.94       933\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.86      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# net34 = torch.load(\"models/resnet34\")\n",
    "pred_34, y_test_34 = run_test(net34)\n",
    "\n",
    "print('ResNet-34 Accuracy: ', accuracy_score(pred_34, y_test_34))\n",
    "print(classification_report(pred_34, y_test_34, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UB_Fmc3VU_A3",
    "outputId": "6bf1a35e-23a8-4b06-f075-a90f9f9cf779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-50 Accuracy:  0.8188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.82      0.73      0.77      1128\n",
      "     Trouser       0.92      0.99      0.95       934\n",
      "    Pullover       0.83      0.63      0.72      1318\n",
      "       Dress       0.80      0.85      0.82       949\n",
      "        Coat       0.69      0.75      0.72       926\n",
      "      Sandal       0.91      0.95      0.93       957\n",
      "       Shirt       0.41      0.56      0.47       739\n",
      "     Sneaker       0.96      0.84      0.90      1143\n",
      "         Bag       0.94      0.95      0.95       985\n",
      "  Ankle boot       0.90      0.97      0.93       921\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# net50 = torch.load(\"models/resnet50\")\n",
    "pred_50, y_test_50 = run_test(net50)\n",
    "\n",
    "print('ResNet-50 Accuracy: ', accuracy_score(pred_50, y_test_50))\n",
    "print(classification_report(pred_50, y_test_50, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gqJwz42U_A4",
    "outputId": "3528684d-93eb-42c5-dfc2-8717f54706b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-101 Accuracy:  0.832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.86      0.72      0.78      1198\n",
      "     Trouser       0.90      1.00      0.95       904\n",
      "    Pullover       0.72      0.75      0.74       969\n",
      "       Dress       0.86      0.79      0.82      1092\n",
      "        Coat       0.76      0.72      0.74      1046\n",
      "      Sandal       0.93      0.95      0.94       979\n",
      "       Shirt       0.46      0.60      0.52       762\n",
      "     Sneaker       0.94      0.91      0.92      1031\n",
      "         Bag       0.94      0.94      0.94       999\n",
      "  Ankle boot       0.96      0.94      0.95      1020\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# net101 = torch.load(\"models/resnet101\")\n",
    "pred_101, y_test_101 = run_test(net101)\n",
    "\n",
    "print('ResNet-101 Accuracy: ', accuracy_score(pred_101, y_test_101))\n",
    "print(classification_report(pred_101, y_test_101, target_names=labels_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m_n6IHmU_A5"
   },
   "source": [
    "The results show that the test accuracy of the three ResNets has reached more than 80% even close to 90%, which is basically in line with expectations. If we use deeper networks such as ResNet-152, or increase the number of epochs `NUM_EPOCHS`, the performance of the model will be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ll62Nh11U_A5"
   },
   "source": [
    "# <a id=\"sec5\"></a>5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWz2VFvzU_A5"
   },
   "source": [
    "ResNet has great advantages in deepening the network model and improving the accuracy of learning tasks.\n",
    "\n",
    "$1$. Network architecture design:\n",
    "\n",
    "- All use 3Ã—3 convolution kernels (or most of them)\n",
    "- Spatial size /2 -> filterÃ—2 (guarantee consistent time complexity)\n",
    "- No dropout layer\n",
    "\n",
    "$2$. The experimental results show that ResNet can be trained without any difficulty, and achieve a deeper network structure to achieve lower training error and test error.\n",
    "\n",
    "$3$. Problem analysis of the deep learning networks and some countermeasures proposed:\n",
    "\n",
    "- Characterization ability: ResNet does not have obvious advantages in characterization ability (just repeated parameterization), but it can make the deepening network feasible.\n",
    "- Easy to optimize: ResNet can make the forward/back propagation algorithm more stable (by adding Batch Normolization), greatly simplify and make it easier for the optimization of the deep networks.\n",
    "- Generalization ability: ResNet does not directly consider generalization, but making the network deeper and thinner is a good generalization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jxSNYrsU_A5"
   },
   "source": [
    "# Sources\n",
    "\n",
    "Here is the list of all the links and ressources of this notebook in order of appearance.\n",
    "\n",
    "[1] [Deep Residual Learning for Image Recognition, Kaiming He et al.](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n",
    "\n",
    "[2] [Learning Long-Term Dependencies with Gradient Descent is Difficult, Y. Bengio et al.](https://ieeexplore-ieee-org.rev-doc.isae.fr/stamp/stamp.jsp?tp=&arnumber=279181)\n",
    "\n",
    "[3] [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification, Kaiming He et al.](https://arxiv.org/pdf/1502.01852.pdf)\n",
    "\n",
    "[4] [Batch normalization: Accelerating deep network training by reducing internal covariate shift, S. Ioffe et al.](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "\n",
    "[5] [Caffe: Convolutional Architecture for Fast Feature Embedding, Y. Q. Jia et al.](https://arxiv.org/pdf/1408.5093.pdf)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
